<div id="logo">
    <img src="../static/banner.png">
</div>
<div id="badges">
    <p align="center">
        <img alt="GitHub Downloads (all assets, all releases)" src="https://img.shields.io/github/downloads/BKDDFS/PerfectFrameAI/total?style=flat&color=blue">
        <img alt="GitHub License" src="https://img.shields.io/github/license/BKDDFS/PerfectFrameAI">
        <img alt="GitHub Release" src="https://img.shields.io/github/v/release/BKDDFS/PerfectFrameAI">
        <img alt="GitHub Repo stars" src="https://img.shields.io/github/stars/BKDDFS/PerfectFrameAI">
    </p>
</div>
<div id="navigation">
    <p align="center">
        <a href="#about">O projekcie</a> &nbsp;&bull;&nbsp;
        <a href="#key-features">Kluczowe Funkcje</a> &nbsp;&bull;&nbsp;
        <a href="#installation">Instalacja</a> &nbsp;&bull;&nbsp;
        <a href="#usage">Jak uÅ¼ywaÄ‡</a> &nbsp;&bull;&nbsp;
        <a href="#contributions">Contribute</a> &nbsp;&bull;&nbsp;
        <a href="#feedback">Feedback</a> &nbsp;&bull;&nbsp;
        <a href="#licence">Licencja</a>
    </p>
</div>
<div id="languages">
    <p align="center">
        <a href="/README.md">English</a> &nbsp;&bull;&nbsp;
        <a href="/README.pl.md">Polski</a>
    </p>
</div>
<div id="description">
    W Å›wiecie przesyconym treÅ›ciami wideo, kaÅ¼da sekunda ma potencjaÅ‚, by staÄ‡ siÄ™ niezapomnianym ujÄ™ciem.
    <code>PerfectFrameAI</code> to narzÄ™dzie wykorzystujÄ…ce sztucznÄ… inteligencjÄ™ do analizowania materiaÅ‚Ã³w wideo
    i automatycznego zapisywania najÅ‚adniejszych klatek.
</div>
<div id="demo">
    <h2>ğŸ” Demo</h2>
    <img src="../static/demo.gif" width="1000">
    <p>Full demo: <a href="https://youtu.be/FX1modlxeWA">https://youtu.be/FX1modlxeWA</a></p>
    <img src="../static/presentation.png" width="1000">
</div>
<div id="key-features">
    <h2>ğŸ”‘ Kluczowe funkcje:</h2>
    <details>
        <summary>
            <strong>Best Frames Extraction ğŸï¸âœğŸ–¼ï¸</strong>
            <blockquote>Wybieranie najlepszych klatek z plikÃ³w video.</blockquote>
        </summary>
        <img src="../static/start_frames.png" width="350">
        <ol>
            <p>Input: Folder z plikami video <code>.mp4</code>.</p>
            <li>Bierze pierwsze video ze wskazanej lokalizacji.</li>
            <li>
                Dzieli wideo na klatki.
                Klatki sÄ… brane co 1 sekundÄ™ wideo.
                Klatki sÄ… przetwarzane w batchach(seriach).
            </li>
            <li>Ocenia wszystkie klatki w batchu za pomocÄ… modelu AI i nadaje im ocenÄ™ liczbowÄ….</li>
            <li>Dzieli batch klatek na mniejsze grupy.</li>
            <li>Wybiera klatkÄ™ z najwyÅ¼szÄ… ocenÄ… liczbowÄ… z kaÅ¼dej grupy.</li>
            <li>Zapisuje klatki z najlepszymi ocenami w wybranej lokalizacji. </li>
            <p>Output: Klatki zapisane jako <code>.jpg</code>.</p>
        </ol>
    </details>
    <br>
    <details>
        <summary>
            <strong>Top Images Extraction ğŸ–¼ï¸âœğŸ–¼ï¸</strong>
            <blockquote>Wybieranie najlepszych obrazÃ³w z folderu z obrazami.</blockquote>
        </summary>
        <img src="../static/start_images.png" width="350">
        <ol>
            <p>Input: Folder z obrazami <code>.jpg</code>.</p>
            <li>Wczytuje obrazy. Obrazy sÄ… przetwarzane batchach(seriach).</li>
            <li>Ocenia wszystkie obrazy w batchu za pomocÄ… modelu AI i nadaje im ocenÄ™ liczbowÄ….</li>
            <li>
                Oblicza, jaki wynik musi mieÄ‡ obraz, Å¼eby znaleÅºÄ‡ siÄ™ w top 90% obrazÃ³w.
                W <code>schemas.py</code> moÅ¼na zmieniÄ‡ tÄ™ wartoÅ›Ä‡ - <code>top_images_percent</code>.
            </li>
            <li>Zapisuje obrazy o  w wybranej lokalizacji. </li>
            <p>Output: Obrazy zapisane jako <code>.jpg</code>.</p>
        </ol>
    </details>
</div>
<div id="installation">
    <h2>ğŸ’¿ Instalacja</h2>
    <blockquote>
        <h3 >Wymagania systemowe:</h3>
        <ul>
            <li>Docker</li>
            <li>Python ^3.10 (tylko sposÃ³b 1)</li>
            <li>Nvidia GPU (zalecane)</li>
            <li>10 GB wolnego miejsca na dysku</li>
        </ul> 
    </blockquote>
    <details>
        <summary>Zainstaluj Dokcer:</summary>
        Docker Desktop: <a href="https://www.docker.com/products/docker-desktop/">https://www.docker.com/products/docker-desktop/</a>
    </details>
    <details>
        <summary>Zainstaluj Python v3.10+:</summary>
        MS Store: <a href="https://apps.microsoft.com/detail/9ncvdn91xzqp?hl=en-US&gl=US">https://apps.microsoft.com/detail/9ncvdn91xzqp?hl=en-US&gl=US</a><br>
        Python.org: <a href="https://www.python.org/downloads/">https://www.python.org/downloads/</a>
    </details>
    <details>
        <summary>Pobierz <code>PerfectFrameAI</code></summary>
        <blockquote>
            Aby pobraÄ‡ kod z repozytorium na GitHubie, kliknij przycisk <code>Code</code>,
            a nastÄ™pnie wybierz <code>Download ZIP</code>
            lub skopiuj adres URL i uÅ¼yj polecenia <code>git clone</code> w terminalu.
        </blockquote>
        <img src="../static/install.png" width="300">
    </details>
</div>
<div id="usage">
    <h2>âš¡ Jak uÅ¼ywaÄ‡:</h2>
    <details id="method1">
        <summary>
            <strong style="font-size: 20px;"> ğŸš€ SposÃ³b 1 - CLI </strong>
            <blockquote><p><i>Wymaga Pythona. Jest prosty i wygodny.</i></p></blockquote>
        </summary>
        <p>Uruchom <code>start.py</code> z terminala.</p>
        <p><strong>PrzykÅ‚ad dla Best Frames Extraction:</strong></p>
        <code>python start.py best_frames_extractor</code>
        <table id="flags">
            <caption><strong>DostÄ™pne flagi</strong></caption>
            <thead>
                <tr>
                    <th>Flaga</th>
                    <th>KrÃ³tka</th>
                    <th>Opis</th>
                    <th>Typ</th>
                    <th>DomyÅ›lna wartoÅ›Ä‡</th>
                </tr>
            </thead>
            <tbody>
                <tr>
                    <td>--input_dir</td>
                    <td>-i</td>
                    <td>Zmiana inputu</td>
                    <td>str</td>
                    <td>./input_directory</td>
                </tr>
                <tr>
                    <td>--output_dir</td>
                    <td>-o</td>
                    <td>Zmiana outputu</td>
                    <td>str</td>
                    <td>./output_directory</td>
                </tr>
                <tr>
                    <td>--port</td>
                    <td>-p</td>
                    <td>Zmiana portu na ktÃ³rym bÄ™dzie dziaÅ‚aÅ‚ <code>extractor_service</code></td>
                    <td>int</td>
                    <td>8100</td>
                </tr>
                <tr>
                    <td>--build</td>
                    <td>-b</td>
                    <td>
                        Buduje nowy Docker image z nowymi podanymi ustawieniami.
                        UÅ¼ywaj zawsze z flagÄ… --build, jeÅ›li nie rozumiesz.
                    </td>
                    <td>bool</td>
                    <td>False</td>
                </tr>
            </tbody>
        </table>
        <p><strong>PrzykÅ‚ad dla Best Frames Extraction:</strong></p> 
        <img src="../static/start_example.png">
        <p>Inne domyÅ›lne parametry moÅ¼esz edytowaÄ‡ w config.py.</p>
        <blockquote>
            <p><strong style="color: lightblue;">UÅ‚atwienie dla uÅ¼ytkownikÃ³w Windows:</strong><br>
            JeÅ›li korzystasz z Windows, moÅ¼esz skorzystaÄ‡ z doÅ‚Ä…czonego pliku <code>quick_demo.bat</code>,
            ktÃ³ry wÅ‚Ä…czy best_frames_extractor na [wartoÅ›ciach domyÅ›lnych] zapisanych w config.py.
            MoÅ¼esz zmieniÄ‡ config.py, Å¼eby dopasowaÄ‡ aplikacjÄ™ do swoich potrzeb.</p>
        </blockquote>
    </details>
    <details id="method2">
        <summary>
            <strong style="font-size: 20px;">ğŸ³ SposÃ³b 2 - docker-compose.yaml:</strong>
            <blockquote><p><i>Nie wymaga Pythona. Uruchom uÅ¼ywajÄ…c Docker Compose.</i></p></blockquote>
        </summary>
        <p>Docker Compose Docs: <a href="https://docs.docker.com/compose/">https://docs.docker.com/compose/</a></p>
        <ol>
            <li>Uruchom serwis: <br><code>docker-compose up --build -d</code></li>
            <li>WyÅ›lij zapytanie pod wybrany endpoint.
            <p><strong>PrzykÅ‚adowe zapytania:</strong></p>
                <ul>
                    <li>Best Frames Extraction:<br><code>POST http://localhost:8100/extractors/best_frames_extractor</code></li>
                    <li>Top Frames Extraction:<br><code>POST http://localhost:8100/extractors/top_images_extractor</code></li>
                    <li>Obecnie pracujÄ…cy extractor:<br><code>GET http://localhost:8100/</code></li>
                </ul>
            </li>
            MoÅ¼esz ewentualnie edytowaÄ‡ docker-compose.yaml, jeÅ›li nie chcesz korzystaÄ‡ z ustawieÅ„ domyÅ›lnych.
        </ol>
    </details>
</div>
<div id="about">
    <h2>ğŸ’¡O projekcie:</h2>
    <div id="contents">
        <h3>Spis treÅ›ci:</h3>
        <a href="#how-it-works">Jak to dziaÅ‚a</a><br>
        &nbsp&nbsp&nbsp&nbsp<a href="#input">Input modelu</a><br>
        &nbsp&nbsp&nbsp&nbsp<a href="#output">Wyniki oceniania obrazÃ³w</a><br>
        &nbsp&nbsp&nbsp&nbsp<a href="#classes">Klasy estetyczne</a><br>
        &nbsp&nbsp&nbsp&nbsp<a href="#calculating-mean">Obliczanie ostatecznej oceny obrazu</a><br>
        <a href="#implementation">Jak to jest zaimplementowane w skrÃ³cie</a><br>
        &nbsp&nbsp&nbsp&nbsp<a href="#model-architecture">Architektura modelu</a><br>
        &nbsp&nbsp&nbsp&nbsp<a href="#weights">Wagi modelu</a><br>
        &nbsp&nbsp&nbsp&nbsp<a href="#normalization">Normalizacja obrazÃ³w</a><br>
        &nbsp&nbsp&nbsp&nbsp<a href="#predictions">Przewidywanie przynaleÅ¼noÅ›ci do klas</a><br>
        &nbsp&nbsp&nbsp&nbsp<a href="#mean-calculation">Obliczanie Å›redniej waÅ¼onej</a><br>
        <a href="#1vs2">v1.0 vs v2.0</a><br>
        <a href="#build-with">UÅ¼yte technologie</a><br>
        <a href="#tests">Testy</a><br>
        &nbsp&nbsp&nbsp&nbsp<a href="#unit">jednostkowe</a><br>
        &nbsp&nbsp&nbsp&nbsp<a href="#integration">integracyjne</a><br>
        &nbsp&nbsp&nbsp&nbsp<a href="#e2e">e2e</a><br>
    </div>
    <div id="how-it-works">
    <h2>ğŸ“ Jak to dziaÅ‚a</h2>
    <p>
        NarzÄ™dzie uÅ¼ywa modelu zbudowanego zgodnie z zasadami dla modeli
        Neural Image Assessment (NIMA) do okreÅ›lania estetyki obrazÃ³w.
    </p>
    <img src="../static/evaluation.png" width="700" style="border-radius: 10px;">
    <details id="input">
       <summary style="font-size: 20px;"><strong>Input modelu</strong></summary>
       <p>Model przyjmuje odpowiednio znormalizowane obrazy w batchu Tensor.</p>
    </details>
    <h3 id="output">Wyniki oceniania obrazÃ³w</h3>
    <p>
    Model NIMA, po przetworzeniu obrazÃ³w, zwraca wektory prawdopodobieÅ„stw, 
    gdzie kaÅ¼da z wartoÅ›Ä‡ w wektorze odpowiada prawdopodobieÅ„stwu, 
    Å¼e obraz przynaleÅ¼y do jednej z klas estetycznych.
    </p>
    <details id="classes">
        <summary style="font-size: 20px;"><strong>Klasy estetyczne</strong></summary>
        <p>
            Jest 10 klas estetycznych. W modelu NIMA kaÅ¼da z 10 klas odpowiada
            okreÅ›lonemu poziomowi estetyki, gdzie:
        </p>
        <ul>
            <li>Klasa 1: Bardzo niska jakoÅ›Ä‡ estetyczna.</li>
            <li>Klasa 2: Niska jakoÅ›Ä‡ estetyczna.</li>
            <li>Klasa 3: PoniÅ¼ej Å›redniej jakoÅ›ci estetycznej.</li>
             ...
            <li>Klasa 10: WyjÄ…tkowo wysoka jakoÅ›Ä‡ estetyczna.</li>
        </ul>
    </details>
    <h3 id="calculating-mean">Obliczanie ostatecznej oceny obrazu</h3>
    <p>
        Ostateczna ocena obrazu jest obliczana za pomocÄ… Å›redniej
        waÅ¼onej z wynikÃ³w dla kaÅ¼dej z klas, gdzie wagi sÄ… 
        wartoÅ›ciami klas od 1 do 10.
    </p>
    <h4>PrzykÅ‚ad:</h4>
    <p>
       ZaÅ‚Ã³Å¼my, Å¼e model zwraca nastÄ™pujÄ…cy wektor 
       prawdopodobieÅ„stw dla jednego obrazu:
    </p>
    <pre>[0.1, 0.05, 0.05, 0.1, 0.2, 0.15, 0.1, 0.1, 0.1, 0.05]</pre>
    Oznacza to, Å¼e obraz ma:
    <ul>
        <li>10% prawdopodobieÅ„stwa przynaleÅ¼noÅ›ci do klasy 1</li>
        <li>5% prawdopodobieÅ„stwa przynaleÅ¼noÅ›ci do klasy 2</li>
        <li>5% prawdopodobieÅ„stwa przynaleÅ¼noÅ›ci do klasy 3</li>
        <li>i tak dalej...</li>
    </ul>
    <p>
       ObliczajÄ…c Å›redniÄ… waÅ¼onÄ… z tych prawdopodobieÅ„stw,
       gdzie wagi to wartoÅ›ci klas (1 do 10):
    </p>
    <img src="../static/weighted_mean.png" width="700">
    </div>
    <div id="implementation">
        <h2>ğŸ“– Implementacja w skrÃ³cie</h2>
        <img src="../static/implementation.png" width="700" style="border-radius: 10px;">
        <details id="model-architecture">
            <summary><strong>Architektura modelu</strong></summary>
            <p>
                Model NIMA uÅ¼ywa architektury InceptionResNetV2 jako swojej podstawy.
                Ta architektura jest znana ze swojej wysokiej wydajnoÅ›ci w zadaniach
                klasyfikacji obrazÃ³w.
            </p>
        </details>
        <details id="weights">
            <summary><strong>Wagi modelu</strong></summary>
            <p>
                Model korzysta z wczeÅ›niej wytrenowanych wag,
                wytrenowanych na duÅ¼ym zbiorze danych (AVA dataset) obrazÃ³w
                ocenionych pod kÄ…tem ich jakoÅ›ci estetycznej.
                NarzÄ™dzie automatycznie pobiera wagi i przechowuje je
                w voluminie Docker do dalszego uÅ¼ytkowania.
            </p>
        </details>
        <details id="normalization">
            <summary><strong>Normalizacja obrazÃ³w</strong></summary>
            <p>
                Przed wprowadzeniem obrazÃ³w do modelu, sÄ… one normalizowane,
                aby upewniÄ‡ siÄ™, Å¼e majÄ… wÅ‚aÅ›ciwy format i zakres wartoÅ›ci.
            </p>
        </details>
        <details id="predictions">
            <summary><strong>Przewidywanie przynaleÅ¼noÅ›ci do klas</strong></summary>
            <p>
                Model przetwarza obrazy i zwraca wektor 10 prawdopodobieÅ„stw,
                z ktÃ³rych kaÅ¼de reprezentuje prawdopodobieÅ„stwo przynaleÅ¼noÅ›ci
                obrazu do jednej z 10 klas jakoÅ›ci estetycznej
                (od 1 dla najniÅ¼szej jakoÅ›ci do 10 dla najwyÅ¼szej jakoÅ›ci).
            </p>
        </details>
        <details id="mean-calculation">
            <summary><strong>Obliczanie Å›redniej waÅ¼onej</strong></summary>
            <p>
                Ostateczny wynik estetyczny dla obrazu jest obliczany
                jako Å›rednia waÅ¼ona tych prawdopodobieÅ„stw,
                przy czym wyÅ¼sze klasy majÄ… wiÄ™ksze wagi.
            </p>
        </details>
    </div>
    <div id="1vs2">
        <h2>âœ… v1.0 vs v2.0</h2>
        <p>
            <code>PerfectFrameAI</code> to narzÄ™dzie stworzone na podstawie jednego z mikro serwisÃ³w mojego gÅ‚Ã³wnego projektu. 
            OkreÅ›lam tamtÄ… wersjÄ™ jako <code>v1.0</code>.
        </p>
        <table>
            <tr>
                <th>Feature</th>
                <th>v1.0</th>
                <th>v2.0</th>
            </tr>
            <tr>
                <td>CLI</td>
                <td class="cross">âŒ</td>
                <td class="check">âœ…</td>
            </tr>
            <tr>
                <td>Zautomatyzowana instalacja</td>
                <td class="cross">âŒ</td>
                <td class="check">âœ…</td>
            </tr>
            <tr>
                <td>Szybki i Prosty Setup</td>
                <td class="cross">âŒ</td>
                <td class="check">âœ…</td>
            </tr>
            <tr>
                <td>WydajnoÅ›Ä‡</td>
                <td>+0%</td>
                <td>+70%</td>
            </tr>
            <tr>
                <td>Rozmiar*</td>
                <td class="cross">12.6 GB</td>
                <td class="check">8.4 GB</td>
            </tr>
            <tr>
                <td>Open Source</td>
                <td class="cross">âŒ</td>
                <td class="check">âœ…</td>
            </tr>
        </table>
        <p>*v1.0 wszystkie zaleÅ¼noÅ›ci i model vs v2.0 docker image + model</p>
        <h3>PorÃ³wnanie wydajnoÅ›ci:</h3>
        <ul>
            <h4>Platforma:</h4>
            <li>RTX3070ti (8GB)</li>
            <li>i5-13600k</li>
            <li>32GB RAM</li>
        </ul>
        <img src="../static/performance.png" height="200">
    </div>
    <div id="build-with">
    <h2>ğŸ› ï¸ UÅ¼yte technologie</h2>
    <ul>
        <li>Python - gÅ‚Ã³wny jÄ™zyk w ktÃ³rym jest napisany projekt.
            ZewnÄ™trzna czÄ™Å›Ä‡ <code>PerfectFrameAI</code> uÅ¼ywa tylko standardowych biblotek Pythona dla uÅ‚atwienia instalacji i kofiguracji narzÄ™dzia.</li>
        <li>FastAPI - framework na ktÃ³rym zostaÅ‚a zbudowana gÅ‚Ã³wna czÄ™Å›Ä‡ <code>PerfectFrameAI</code> (w v1.0 Flask).</li>
        <li>OpenCV - do manipulacji obrazami.</li>
        <li>numpy - do operacji na tablicach wielowymiarowych.</li>
        <li>FFMPEG - jako rozszerzenie do OpenCV, do dekodowania klatek video.</li>
        <li>CUDA - do umoÅ¼liwienia wykonywania operacji na kartach graficznych.</li>
        <li>Tensorflow - wykorzystywana bibloteka do uczenia maszynowego (w v1.0 PyTorch).</li>
        <li>Docker - dla uÅ‚atwienia budowania skÄ…plikowanego Å›rodowiska pracy dla <code>PerfectFrameAI</code>.</li>
        <li>pytest - framework w ktÃ³rym napisane sÄ… testy.</li>
        <li>docker-py - uÅ¼ywany jedynie do testowania integracji Dockera z doÅ‚Ä…czonym managerem <code>PerfectFrameAI</code>.</li>
        <li>Poetry - do zaÅ¼Ä…dzania zaleÅ¼noÅ›ciami projektu.</li>
        <blockquote>Wszystkie uÅ¼ywane zaleÅ¼noÅ›ci dostÄ™pne sÄ… w <a href="https://github.com/BKDDFS/PerfectFrameAI/blob/main/pyproject.toml">pyproject.toml.</a></blockquote>
    </ul>
    </div>
    <div id="tests">
        <h2>ğŸ§ª Testy</h2>
        <img src="../static/tests_passed.png">
        <p>
            Testy moÅ¼esz uruchomiÄ‡ instalujÄ…c zaleÅ¼noÅ›ci z <code>pyproject.toml</code>
            i wpisujÄ…c w terminal w lokalizacj projektu - <code>pytest</code>.
        </p>
        <blockquote>
            ProszÄ™ zwrÃ³ciÄ‡ uwagÄ™, Å¼e w projekcie sÄ… dwa foldery <code>tests/</code>.
            <code>extractor_service</code> i <code>service_initializer</code> majÄ… testy osobno.
            W pliku common.py znajdujÄ… siÄ™ pliki wpÃ³Å‚dzielone przez testy i potrzebne do ich dziaÅ‚ania.
        </blockquote>
        <details id="unit">
            <summary>jednostkowe</summary>
            <p>
            KaÅ¼dy moduÅ‚ ma swoje testy jednostkowe.
            TestujÄ… one kaÅ¼dÄ… z metod i funkcji dostÄ™pnych w moduÅ‚ach.
            Test coverage wynosi 100% (testy w caÅ‚oÅ›ci pokrywajÄ… logikÄ™ biznesowÄ…).
            </p>
        </details>
        <details id="integration">
            <summary>integracyjne</summary>
            <ul>
                <li>Testowanie integracji docker_manager z Dockerem.</li>
                <li>Testowanie integracji z parserem.</li>
                <li>Testowanie integracji logiki biznesowej z modelem NIMA.</li>
                <li>Testowanie integracji z FastAPI.</li>
                <li>Testowanie integracji z OpenCV.</li>
                <li>Testowanie integracji z FFMPEG.</li>
                <li>Testowanie integracji moduÅ‚Ã³w miÄ™dzy sobÄ… na rÃ³Å¼ne sposoby...</li>
            </ul>
        </details>
        <details id="e2e">
            <summary>e2e</summary>
            <ul>
                <li>Testowanie dziaÅ‚ania extractor_service jako caÅ‚oÅ›Ä‡.</li>
                <li>Testowanie dziaÅ‚ania extractor_service+service_initializer jako caÅ‚oÅ›Ä‡.</li>
            </ul>
        </details>
    </div>
</div>
<div id="roadmap">
    <h2>ğŸ¯ Roadmapa</h2>
        <p>
            PoniÅ¼ej znajduje siÄ™ lista funkcji, ktÃ³re planujemy zaimplementowaÄ‡ w nadchodzÄ…cych wersjach.
            Zapraszamy do wspÃ³Å‚pracy i sugestii spoÅ‚ecznoÅ›Ä‡.
        </p>
        <ul>
            <li>
                Implementacja Nvidia DALI.
                <ul>
                    <li>UmoÅ¼liwi przeniesienie dekodowania klatek (obecnie najdÅ‚uÅ¼szej czÄ™Å›ci) na GPU.</li>
                    <li>Dodatkowo umoÅ¼liwi operowanie od razu na obiektach Tensor bez dodatkowych konwersji.</li>
                </ul>
                PodsumowujÄ…c, dodanie DALI powinno byÄ‡ kolejnym powaÅ¼nym krokiem naprzÃ³d,
                jeÅ›li chodzi o poprawÄ™ wydajnoÅ›ci.
            </li>
            <li>Przetestowanie dziaÅ‚ania na starszych wersjach Pythona.</li>
            <li>
                Naprawienie spillingu danych podczas oceniania klatek. 
                Obecnie ocenianie ma delikatne spowolnienie w postaci problemu ze spillingiem.
            </li>
        </ul>
</div>
<div id="contributions">
    <h2>ğŸ‘‹ Jak zostaÄ‡ Contributorem</h2>
    <p>
        JeÅ›li jesteÅ› zainteresowany wkÅ‚adem w ten projekt,
        proszÄ™ poÅ›wiÄ™Ä‡ chwilÄ™ na przeczytanie naszego 
        <a href="https://github.com/BKDDFS/PerfectFrameAI/blob/main/.github/CONTRIBUTING.md">Przewodnika dla contributorÃ³w</a>.
        Zawiera on wszystkie informacje potrzebne do rozpoczÄ™cia, takie jak:
    </p>
    <ul>
        <li>Jak zgÅ‚aszaÄ‡ bÅ‚Ä™dy i skÅ‚adaÄ‡ proÅ›by o nowe funkcje</li>
        <li>Nasze standardy i wytyczne dotyczÄ…ce kodowania</li>
        <li>Instrukcje dotyczÄ…ce konfiguracji Å›rodowiska developerskiego</li>
        <li>Proces skÅ‚adania pull requestÃ³w</li>
    </ul>
    <p>
        TwÃ³j wkÅ‚ad pomaga uczyniÄ‡ ten projekt lepszym, doceniamy twoje wysiÅ‚ki. DziÄ™kujemy za wsparcie!
    </p>
</div>
<div id="feedback">
    <h2>â¤ï¸ Feedback</h2>
    <p>
        BÄ™dÄ™ bardzo wdziÄ™czny za feedback na temat jakoÅ›ci mojego kodu i tego projektu. 
        JeÅ›li masz jakieÅ› sugestie, proszÄ™:
    </p>
    <ul>
        <li>Zostaw komentarze na konkretnych liniach kodu za pomocÄ… pull requestÃ³w.</li>
        <li>
            StwÃ³rz <a href="https://github.com/BKDDFS/PerfectFrameAI/issues">Issue</a>,
            aby omÃ³wiÄ‡ wiÄ™ksze zmiany lub ogÃ³lne sugestie.
        </li>
        <li>WeÅº udziaÅ‚ w dyskusjach w sekcji â€Dyskusjeâ€ tego repozytorium.</li>
    </ul>
    <blockquote>W celu bezpoÅ›redniej komunikacji, moÅ¼esz skontaktowaÄ‡ siÄ™ ze mnÄ… pod adresem <a href="mailto:Bartekdawidflis@gmail.com">Bartekdawidflis@gmail.com</a>.</blockquote>
</div>
<div id="support">
    <h2>â­ï¸ Wsparcie</h2>
    <p>Nie zapomnij zostawiÄ‡ gwiazdki â­ï¸.</p>
</div>
<div id="references">
    <h2>ğŸ—ƒï¸ Biografia</h2>
    Oryginalna publikacja Google Brains przedstawiajÄ…ca NIMA:<br>
    <a href="https://research.google/blog/introducing-nima-neural-image-assessment/">https://research.google/blog/introducing-nima-neural-image-assessment/</a><br>
    Wagi do modelu:<br>
    <a href="https://github.com/titu1994/neural-image-assessment">https://github.com/titu1994/neural-image-assessment</a>
</div>
<div id="licence">
    <h2>ğŸ“œ Licencja</h2>
    <p>
        PerfectFrameAI jest licencjonowany na podstawie licencji GNU General Public License v3.0.
        WiÄ™cej informacji znajdziesz w pliku <a href="https://github.com/BKDDFS/PerfectFrameAI/blob/main/LICENSE">LICENSE</a>.
    </p>
</div>
