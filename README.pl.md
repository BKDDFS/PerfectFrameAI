<div id="logo">
    <img src="static/banner.png">
</div>
<div id="badges">
    <p align="center">
        <img alt="GitHub Downloads (all assets, all releases)" src="https://img.shields.io/github/downloads/BKDDFS/PerfectFrameAI/total?style=flat&color=blue">
        <img alt="GitHub License" src="https://img.shields.io/github/license/BKDDFS/PerfectFrameAI">
        <img alt="GitHub Release" src="https://img.shields.io/github/v/release/BKDDFS/PerfectFrameAI">
        <img alt="GitHub Repo stars" src="https://img.shields.io/github/stars/BKDDFS/PerfectFrameAI">
    </p>
</div>
<div id="navigation">
    <p align="center">
        <a href="#about">O projekcie</a> &nbsp;&bull;&nbsp;
        <a href="#key-features">Funkcje</a> &nbsp;&bull;&nbsp;
        <a href="#installation">Instalacja</a> &nbsp;&bull;&nbsp;
        <a href="#usage">Jak uÅ¼ywaÄ‡</a> &nbsp;&bull;&nbsp;
        <a href="#contributions">Contributions</a> &nbsp;&bull;&nbsp;
        <a href="#feedback">Feedback</a> &nbsp;&bull;&nbsp;
        <a href="#licence">Licencja</a>
    </p>
</div>
<div id="languages">
    <p align="center">
        <a href="/README.md">English</a> &nbsp;&bull;&nbsp;
        <a href="/README.pl.md">Polski</a>
    </p>
</div>
<div id="description">
    W Å›wiecie przesyconym treÅ›ciami wideo, kaÅ¼da sekunda ma potencjaÅ‚, by staÄ‡ siÄ™ niezapomnianym ujÄ™ciem.
    <code>PerfectFrameAI</code> to narzÄ™dzie wykorzystujÄ…ce sztucznÄ… inteligencjÄ™ do analizowania materiaÅ‚Ã³w wideo
    i automatycznego zapisywania najÅ‚adniejszych klatek.
</div>
<div id="demo">
    <h2>ğŸ” Demo</h2>
    <img src="static/demo.gif" width="1000">
    <p>Full video: <a href="https://youtu.be/FX1modlxeWA">https://youtu.be/FX1modlxeWA</a></p>
</div>
<div id="key-features">
    <h2>ğŸ”‘ Kluczowe funkcje:</h2>
    <details>
        <summary>
            <strong>Best Frames Extraction ğŸï¸âœğŸ–¼ï¸</strong>
            <blockquote>Wybieranie najlepszych klatek z plikÃ³w video.</blockquote>
        </summary>
        <img src="static/start_frames.png" width="350">
        <ol>
            <p>Input: Folder z plikami video <code>.mp4</code>.</p>
            <li>Bierze pierwsze video ze wskazanej lokalizacji.</li>
            <li>
                Dzieli wideo na klatki.
                Klatki sÄ… brane co 1 sekundÄ™ wideo.
                Klatki sÄ… przetwarzane w batchach(seriach).
            </li>
            <li>Ocenia wszystkie klatki w batchu za pomocÄ… modelu AI i nadaje im ocenÄ™ liczbowÄ….</li>
            <li>Dzieli batch klatek na mniejsze grupy.</li>
            <li>Wybiera klatkÄ™ z najwyÅ¼szÄ… ocenÄ… liczbowÄ… z kaÅ¼dej grupy.</li>
            <li>Zapisuje klatki z najlepszymi ocenami w wybranej lokalizacji. </li>
            <p>Output: Klatki zapisane jako <code>.jpg</code>.</p>
        </ol>
    </details>
    <br>
    <details>
        <summary>
            <strong>Top Images Extraction ğŸ–¼ï¸âœğŸ–¼ï¸</strong>
            <blockquote>Wybieranie najlepszych obrazÃ³w z folderu z obrazami.</blockquote>
        </summary>
        <img src="static/start_images.png" width="350">
        <ol>
            <p>Input: Folder z obrazami <code>.jpg</code>.</p>
            <li>Wczytuje obrazy. Obrazy sÄ… przetwarzane batchach(seriach).</li>
            <li>Ocenia wszystkie obrazy w batchu za pomocÄ… modelu AI i nadaje im ocenÄ™ liczbowÄ….</li>
            <li>
                Oblicza, jaki wynik musi mieÄ‡ obraz, Å¼eby znaleÅºÄ‡ siÄ™ w top 90% obrazÃ³w.
                W <code>schemas.py</code> moÅ¼na zmieniÄ‡ tÄ™ wartoÅ›Ä‡ - <code>top_images_percent</code>.
            </li>
            <li>Zapisuje obrazy o  w wybranej lokalizacji. </li>
            <p>Output: Obrazy zapisane jako <code>.jpg</code>.</p>
        </ol>
    </details>
</div>
<div id="installation">
    <h2>ğŸ’¿ Instalacja</h2>
    <blockquote>
        <h3 >Wymagania systemowe:</h3>
        <ul>
            <li>Docker</li>
            <li>Python ^3.10 (tylko sposÃ³b 1)</li>
            <li>Nvidia GPU (zalecane)</li>
            <li>10 GB wolnego miejsca na dysku</li>
        </ul> 
    </blockquote>
    <details>
        <summary>Zainstaluj Dokcer:</summary>
        Docker Desktop: <a href="https://www.docker.com/products/docker-desktop/">https://www.docker.com/products/docker-desktop/</a>
    </details>
    <details>
        <summary>Zainstaluj Python v3.10+:</summary>
        MS Store: <a href="https://apps.microsoft.com/detail/9ncvdn91xzqp?hl=en-US&gl=US">https://apps.microsoft.com/detail/9ncvdn91xzqp?hl=en-US&gl=US</a><br>
        Python.org: <a href="https://www.python.org/downloads/">https://www.python.org/downloads/</a>
    </details>
    <details>
        <summary>Pobierz <code>PerfectFrameAI</code></summary>
        <blockquote>
            Aby pobraÄ‡ kod z repozytorium na GitHubie, kliknij przycisk <code>Code</code>,
            a nastÄ™pnie wybierz <code>Download ZIP</code>
            lub skopiuj adres URL i uÅ¼yj polecenia <code>git clone</code> w terminalu.
        </blockquote>
        <img src="static/install.png" width="300">
    </details>
</div>
<div id="usage">
    <h2>âš¡ Jak uÅ¼ywaÄ‡:</h2>
    <details id="method1">
        <summary>
            <strong style="font-size: 20px;"> ğŸš€ SposÃ³b 1 - CLI </strong>
            <blockquote><p><i>Wymaga Pythona. Jest prosty i wygodny.</i></p></blockquote>
        </summary>
        <p>Uruchom <code>start.py</code> z terminala.</p>
        <p><strong>PrzykÅ‚ad dla Best Frames Extraction:</strong></p>
        <code>python start.py best_frames_extractor</code>
        <table id="flags">
            <caption><strong>DostÄ™pne flagi</strong></caption>
            <thead>
                <tr>
                    <th>Flaga</th>
                    <th>KrÃ³tka</th>
                    <th>Opis</th>
                    <th>Typ</th>
                    <th>DomyÅ›lna wartoÅ›Ä‡</th>
                </tr>
            </thead>
            <tbody>
                <tr>
                    <td>--input_dir</td>
                    <td>-i</td>
                    <td>Zmiana inputu</td>
                    <td>str</td>
                    <td>./input_directory</td>
                </tr>
                <tr>
                    <td>--output_dir</td>
                    <td>-o</td>
                    <td>Zmiana outputu</td>
                    <td>str</td>
                    <td>./output_directory</td>
                </tr>
                <tr>
                    <td>--port</td>
                    <td>-p</td>
                    <td>Zmiana portu na ktÃ³rym bÄ™dzie dziaÅ‚aÅ‚ service</td>
                    <td>int</td>
                    <td>8100</td>
                </tr>
                <tr>
                    <td>--build</td>
                    <td>-b</td>
                    <td>
                        Buduje nowy Docker image z nowymi podanymi ustawieniami.
                        UÅ¼ywaj zawsze z flagÄ… --build, jeÅ›li nie rozumiesz.
                    </td>
                    <td>bool</td>
                    <td>False</td>
                </tr>
            </tbody>
        </table>
        <p><strong>PrzykÅ‚ad dla Best Frames Extraction:</strong></p>        
        <code>python start.py best_frames_extractor -p &lt;your_port_here&gt; -i &lt;your_input_dir_here&gt; -o &lt;your_output_dir_here&gt; --build</code><br>
        <p>Inne domyÅ›lne parametry moÅ¼esz edytowaÄ‡ w config.py.</p>
        <blockquote>
            <p><strong style="color: lightblue;">UÅ‚atwienie dla uÅ¼ytkownikÃ³w Windows:</strong><br>
            JeÅ›li korzystasz z Windows, moÅ¼esz skorzystaÄ‡ z doÅ‚Ä…czonego pliku <code>quick_demo.bat</code>,
            ktÃ³ry wÅ‚Ä…czy best_frames_extractor na [wartoÅ›ciach domyÅ›lnych] zapisanych w config.py.
            MoÅ¼esz zmieniÄ‡ config.py, Å¼eby dopasowaÄ‡ aplikacjÄ™ do swoich potrzeb.</p>
        </blockquote>
    </details>
    <details id="method2">
        <summary>
            <strong style="font-size: 20px;">ğŸ³ SposÃ³b 2 - docker-compose.yaml:</strong>
            <blockquote><p><i>Nie wymaga Pythona. Uruchom uÅ¼ywajÄ…c Docker Compose.</i></p></blockquote>
        </summary>
        <p>Docker Compose Docs: <a href="https://docs.docker.com/compose/">https://docs.docker.com/compose/</a></p>
        <ol>
            <li>Uruchom service: <br><code>docker-compose up --build -d</code></li>
            <li>WyÅ›lij zapytanie pod wybrany endpoint.
            <p><strong>PrzykÅ‚adowe zapytania:</strong></p>
                <ul>
                    <li>Best Frames Extraction:<br><code>POST http://localhost:8100/extractors/best_frames_extractor</code></li>
                    <li>Top Frames Extraction:<br><code>POST http://localhost:8100/extractors/top_images_extractor</code></li>
                    <li>Current working extractor:<br><code>GET http://localhost:8100/</code></li>
                </ul>
            </li>
            MoÅ¼esz ewentualnie edytowaÄ‡ docker-compose.yaml, jeÅ›li nie chcesz korzystaÄ‡ z ustawieÅ„ domyÅ›lnych.
        </ol>
    </details>
</div>
<div id="about">
    <h2>ğŸ’¡O projekcie:</h2>
    <div id="contents">
        <h3>Spis treÅ›ci:</h3>
        <a href="#how-it-works">Jak to dziaÅ‚a</a><br>
        &nbsp&nbsp&nbsp&nbsp<a href="#input">Input modelu</a><br>
        &nbsp&nbsp&nbsp&nbsp<a href="#output">Wyniki oceniania obrazÃ³w</a><br>
        &nbsp&nbsp&nbsp&nbsp<a href="#classes">Klasy estetyczne</a><br>
        &nbsp&nbsp&nbsp&nbsp<a href="#calculating-mean">Obliczanie ostatecznej oceny obrazu</a><br>
        <a href="#implementation">Jak to jest zaimplementowane w skrÃ³cie</a><br>
        &nbsp&nbsp&nbsp&nbsp<a href="#model-architecture">Architektura modelu</a><br>
        &nbsp&nbsp&nbsp&nbsp<a href="#weights">Pre-trained Weights</a><br>
        &nbsp&nbsp&nbsp&nbsp<a href="#normalization">Normalizacja obrazÃ³w</a><br>
        &nbsp&nbsp&nbsp&nbsp<a href="#predictions">Przewidywanie przynaleÅ¼noÅ›ci do klas</a><br>
        &nbsp&nbsp&nbsp&nbsp<a href="#mean-calculation">Obliczanie Å›redniej waÅ¼onej</a><br>
        <a href="#1vs2">v1.0 vs v2.0</a><br>
        <a href="#build-with">UÅ¼yte technologie</a><br>
        <a href="#uml">UML</a><br>
        <a href="#tests">Tests</a><br>
        &nbsp&nbsp&nbsp&nbsp<a href="#unit">unit</a><br>
        &nbsp&nbsp&nbsp&nbsp<a href="#integration">integration</a><br>
        &nbsp&nbsp&nbsp&nbsp<a href="#e2e">e2e</a><br>
    </div>
    <div id="how-it-works">
    <h2>Jak to dziaÅ‚a</h2>
    NarzÄ™dzie uÅ¼ywa modelu zbudowanego zgodnie z zasadami dla modeli
    Neural Image Assessment (NIMA) do okreÅ›lania estetyki obrazÃ³w.
    <details id="input">
       <summary style="font-size: 20px;"><strong>Input modelu</strong></summary>
       <p>Model przyjmuje odpowiednio znormalizowane obrazy w batchu Tensor.</p>
    </details>
    <h3 id="output">Wyniki oceniania obrazÃ³w</h3>
    <p>
    Model NIMA, po przetworzeniu obrazÃ³w, zwraca wektory prawdopodobieÅ„stw, 
    gdzie kaÅ¼da z wartoÅ›Ä‡ w wektorze odpowiada prawdopodobieÅ„stwu, 
    Å¼e obraz przynaleÅ¼y do jednej z klas estetycznych.
    </p>
    <details id="classes">
        <summary style="font-size: 20px;"><strong>Klasy estetyczne</strong></summary>
        <p>
            Jest 10 klas estetycznych. W modelu NIMA kaÅ¼da z 10 klas odpowiada
            okreÅ›lonemu poziomowi estetyki, gdzie:
        </p>
        <ul>
            <li>Klasa 1: Bardzo niska jakoÅ›Ä‡ estetyczna.</li>
            <li>Klasa 2: Niska jakoÅ›Ä‡ estetyczna.</li>
            <li>Klasa 3: PoniÅ¼ej Å›redniej jakoÅ›ci estetycznej.</li>
             ...
            <li>Klasa 10: WyjÄ…tkowo wysoka jakoÅ›Ä‡ estetyczna.</li>
        </ul>
    </details>
    <h3 id="calculating-mean">Obliczanie ostatecznej oceny obrazu</h3>
    <p>
        Ostateczna ocena obrazu jest obliczana za pomocÄ… Å›redniej
        waÅ¼onej z wynikÃ³w dla kaÅ¼dej z klas, gdzie wagi sÄ… 
        wartoÅ›ciami klas od 1 do 10.
    </p>
    <h4>PrzykÅ‚ad:</h4>
    <p>
       ZaÅ‚Ã³Å¼my, Å¼e model zwraca nastÄ™pujÄ…cy wektor 
       prawdopodobieÅ„stw dla jednego obrazu:
    </p>
    <pre>[0.1, 0.05, 0.05, 0.1, 0.2, 0.15, 0.1, 0.1, 0.1, 0.05]</pre>
    Oznacza to, Å¼e obraz ma:
    <ul>
        <li>10% prawdopodobieÅ„stwa przynaleÅ¼noÅ›ci do klasy 1</li>
        <li>5% prawdopodobieÅ„stwa przynaleÅ¼noÅ›ci do klasy 2</li>
        <li>5% prawdopodobieÅ„stwa przynaleÅ¼noÅ›ci do klasy 3</li>
        <li>i tak dalej...</li>
    </ul>
    <p>
       ObliczajÄ…c Å›redniÄ… waÅ¼onÄ… z tych prawdopodobieÅ„stw,
       gdzie wagi to wartoÅ›ci klas (1 do 10):
    </p>
    <img src="static/weighted_mean.png" width="700">
    </div>
    <div id="implementation">
        <h2>Jak to jest zaimplementowane w skrÃ³cie</h2>
        <details id="model-architecture">
            <summary><strong>Architektura modelu</strong></summary>
            <p>The NIMA model uses the InceptionResNetV2 architecture as its base. This architecture is known for its high performance in image classification tasks.</p>
        </details>
        <details id="weights">
            <summary><strong>Pre-trained Weights</strong></summary>
            <p>The model uses pre-trained weights that have been trained on a large dataset (AVA dataset) of images rated for their aesthetic quality. NarzÄ™dzie pobiera automatycznie wagi i przechowuje je w voluminie docker do dalszego uÅ¼ytkowania.</p>
        </details>
        <details id="normalization">
            <summary><strong>Image Normalization</strong></summary>
            <p>Before feeding images into the model, they are normalized to ensure they are in the correct format and value range.</p>
        </details>
        <details id="predictions">
            <summary><strong>Przewidywanie przynaleÅ¼noÅ›ci do klas</strong></summary>
            <p>The model processes the images and returns a vector of 10 probabilities, each representing the likelihood of the image belonging to one of the 10 aesthetic quality classes (from 1 for the lowest quality to 10 for the highest quality).</p>
        </details>
        <details id="mean-calculation">
            <summary><strong>Obliczanie Å›redniej waÅ¼onej</strong></summary>
            <p>The final aesthetic score for an image is calculated as the weighted mean of these probabilities, with higher classes having greater weights.</p>
        </details>
    </div>
    <div id="1vs2">
        <h2>v1.0 vs v2.0</h2>
        <p>
            <code>PerfectFrameAI</code> to narzÄ™dzie stworzone na podstawie jednego z mikro serwisÃ³w mojego gÅ‚Ã³wnego projektu. 
            OkreÅ›lam tamtÄ… wersjÄ™ jako <code>v1.0</code>.
        </p>
        <img src="static/1vs2.png">
    </div>
    <div id="build-with">
    <h2>ğŸ› ï¸ Build with</h2>
    <ul>
        <li>Python - gÅ‚Ã³wny jÄ™zyk w ktÃ³rym jest napisany projekt.
            ZewnÄ™trzna czÄ™Å›Ä‡ <code>PerfectFrameAI</code> uÅ¼ywa tylko standardowych biblotek Pythona dla uÅ‚atwienia instalacji i kofiguracji narzÄ™dzia.</li>
        <li>FastAPI - framework na ktÃ³rym zostaÅ‚a zbudowana gÅ‚Ã³wna czÄ™Å›Ä‡ <code>PerfectFrameAI</code> (w v1.0 Flask).</li>
        <li>OpenCV - do manipulacji obrazami.</li>
        <li>numpy - do operacji na tablicach wielowymiarowych.</li>
        <li>FFMPEG - jako rozszerzenie do OpenCV, do dekodowania klatek video.</li>
        <li>CUDA - do umoÅ¼liwienia wykonywania operacji na kartach graficznych.</li>
        <li>Tensorflow - wykorzystywana bibloteka do uczenia maszynowego (w v1.0 PyTorch).</li>
        <li>Docker - dla uÅ‚atwienia budowania skÄ…plikowanego Å›rodowiska pracy dla <code>PerfectFrameAI</code>.</li>
        <li>pytest - framework w ktÃ³rym napisane sÄ… testy.</li>
        <li>docker-py - uÅ¼ywany jedynie do testowania integracji Dockera z doÅ‚Ä…czonym managerem <code>PerfectFrameAI</code>.</li>
        <li>Poetry - do zaÅ¼Ä…dzania zaleÅ¼noÅ›ciami projektu.</li>
        <blockquote>Wszystkie uÅ¼ywane zaleÅ¼noÅ›ci dostÄ™pne sÄ… w <a href="pyproject.toml">pyproject.toml.</a></blockquote>
    </ul>
    </div>
    <div id="uml">
    <h3>UML</h3>
    <p>#TODO</p>
    </div>
    <div id="tests">
        <h3>Tests</h3>
        <img src="static/tests_passed.png">
        <p>
            Testy moÅ¼esz uruchomiÄ‡ instalujÄ…c zaleÅ¼noÅ›ci z <code>pyproject.toml</code>
            i wpisujÄ…c w terminal w lokalizacj projektu - <code>pytest</code>.
        </p>
        <blockquote>
            ProszÄ™ zwrÃ³ciÄ‡ uwagÄ™, Å¼e w projekcie sÄ… dwa foldery <code>tests/</code>.
            <code>extractor_service</code> i <code>service_initializer</code> majÄ… testy osobno.
            W pliku common.py znajdujÄ… siÄ™ pliki wpÃ³Å‚dzielone przez testy i potrzebne do ich dziaÅ‚ania.
        </blockquote>
        <details id="unit">
            <summary>unit</summary>
            <p>
            KaÅ¼dy moduÅ‚ ma swoje testy jednostkowe.
            TestujÄ… one kaÅ¼dÄ… z metod i funkcji dostÄ™pnych w moduÅ‚ach.
            Test coverage wynosi 100% (testy w caÅ‚oÅ›ci pokrywajÄ… logikÄ™ biznesowÄ…).
            </p>
        </details>
        <details id="integration">
            <summary>integration</summary>
            <ul>
                <li>Testowanie integracji docker_manager z Dockerem.</li>
                <li>Testowanie integracji z parserem.</li>
                <li>Testowanie integracji logiki biznesowej z modelem NIMA.</li>
                <li>Testowanie integracji z FastAPI.</li>
                <li>Testowanie integracji z OpenCV.</li>
                <li>Testowanie integracji z FFMPEG.</li>
                <li>Testowanie integracji moduÅ‚Ã³w miÄ™dzy sobÄ… na rÃ³Å¼ne sposoby...</li>
            </ul>
        </details>
        <details id="e2e">
            <summary>e2e</summary>
            <ul>
                <li>Testowanie dziaÅ‚ania extractor_service jako caÅ‚oÅ›Ä‡.</li>
                <li>Testowanie dziaÅ‚ania extractor_service+service_initializer jako caÅ‚oÅ›Ä‡.</li>
            </ul>
        </details>
    </div>
</div>
<div id="roadmap">
    <h2>ğŸ¯ Roadmap</h2>
        <p>
            Below is a list of features that we are planning to implement in the upcoming releases.
            We welcome contributions and suggestions from the community.
        </p>
        <ul>
            <li>
                Implementacja Nvidia DALI.
                <ul>
                    <li>UmoÅ¼liwi przeniesienia dekodowania klatek (obecnie najdÅ‚uÅ¼szej czÄ™Å›ci) na GPU.</li>
                    <li>Dodatkowo umoÅ¼liwi operowanie od razu na obiektach Tensor bez dodatkowych konwersji.</li>
                </ul>
                PodsumowujÄ…c dodanie DALI powinno byÄ‡ kolejny powaÅ¼nym krokiem naprzÃ³d,
                jeÅ›li chodzi o poprawÄ™ wydajnoÅ›ci.
            </li>
            <li>Przetestowanie dziaÅ‚ania na starszych wersjach Pythona.</li>
            <li>
                Naprawienie spillingu danych podczas oceniania klatek. 
                Obecnie ocenianie ma delikatne spowolnienie w postaci problemu ze spillingiem.
            </li>
        </ul>
</div>
<div id="contributions">
    <h2>ğŸ‘‹ How to Contribute</h2>
    <p>
        We welcome contributions from the community!
        If you're interested in contributing to this project,
        please take a moment to read our <a href=".github/CONTRIBUTING.md">Contribution Guide</a>. It includes all the information you need to get started, such as:
    </p>
    <ul>
        <li>How to report bugs and submit feature requests</li>
        <li>Our coding standards and guidelines</li>
        <li>Instructions for setting up your development environment</li>
        <li>The process for submitting pull requests</li>
    </ul>
    <p>
        Your contributions help make this project better, and we appreciate your efforts. Thank you for your support!
    </p>
</div>
<div id="feedback">
    <h2>â¤ï¸ How to Give Feedback</h2>
    <p>I am looking for feedback on the code quality and design of this project. If you have any suggestions on how to improve the code, please feel free to:</p>
    <ul>
        <li>Leave comments on specific lines of code via pull requests.</li>
        <li>Open an issue to discuss larger changes or general suggestions.</li>
        <li>Participate in discussions in the 'Discussions' section of this repository.</li>
    </ul>
    <p>Your insights are invaluable and greatly appreciated as they will help improve the project and my skills as a developer.</p>
    <blockquote>For more direct communication, you can reach me at <a href="Bartekdawidflis@gmail.com">Bartekdawidflis@gmail.com</a>.</blockquote>
</div>
<div id="support">
    <h2>â­ï¸ Support</h2>
    <p>Don't forget to leave a star â­ï¸.</p>
</div>
<div id="references">
    <h2>References</h2>
    Oryginalna publikacja Google Brains przedstawiajÄ…ca NIMA: 
            <a href="https://research.google/blog/introducing-nima-neural-image-assessment/">https://research.google/blog/introducing-nima-neural-image-assessment/</a><br>
    <a href="https://research.google/blog/introducing-nima-neural-image-assessment/">Google Brain Blog Post on NIMA</a>
    Source of pre-trained weights: <a href="">https://github.com/titu1994/neural-image-assessment</a>
    </div>
<div id="licence">
    <h2>ğŸ“œ Licencja</h2>
    <p>
        PerfectFrameAI is licensed under the GNU General Public License v3.0.
        See the <a href="/LICENSE">LICENSE</a> file for more information.
    </p>
</div>
